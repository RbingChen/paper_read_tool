<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<style>
  body { font-family: Arial, sans-serif; line-height: 1.6; }
  .original { background-color: #f0f0f0; border: 1px solid #cccccc; padding: 15px; margin-bottom: 10px; }
  .translation { background-color: #e0ffe0; border: 1px solid #00cc00; padding: 15px; margin-bottom: 20px; }
  .figure { background-color: #ffffcc; padding: 15px; margin: 20px 0; }
  .formula-container { text-align: center; margin: 20px 0; }
  .formula-number { display: block; text-align: right; font-style: italic; margin-top: 5px; }
  .term { color: red; font-weight: bold; }
  h2 { color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 5px; }
  h3 { color: #2980b9; }
  dt { font-weight: bold; margin-top: 10px; }
</style>
</head>
<body>

<h2>å†…å®¹ç†è§£</h2>
<div>
  <p>è¯¥æŠ€æœ¯æŠ¥å‘Šä»‹ç»äº†<strong class="term">OneRec</strong>æ¨èç³»ç»Ÿä¸­çš„å¤šæ¨¡æ€è¡¨ç¤ºå­¦ä¹ æ¡†æ¶ã€‚æ ¸å¿ƒæ˜¯é€šè¿‡<strong class="term">QFormer</strong>å‹ç¼©å¤šæ¨¡æ€ç‰¹å¾ï¼Œå¹¶åˆ©ç”¨<strong class="term">ååŒè¿‡æ»¤</strong>æ„å»ºé¡¹ç›®å¯¹æ•°æ®é›†ã€‚ç³»ç»Ÿæ•´åˆè§†é¢‘çš„<strong class="term">æ ‡é¢˜ï¼ˆCaptionï¼‰</strong>ã€<strong class="term">æ ‡ç­¾ï¼ˆTagï¼‰</strong>ã€<strong class="term">OCR</strong>ã€<strong class="term">ASR</strong>ã€å°é¢å’Œå¸§ä¿¡æ¯ï¼Œé€šè¿‡<strong class="term">miniCPM-V-8B</strong>ç”Ÿæˆåˆå§‹è¡¨ç¤ºï¼Œå†ç»<strong class="term">QFormer</strong>å‹ç¼©ä¸ºä½ç»´å‘é‡ã€‚è®­ç»ƒé‡‡ç”¨åŒç›®æ ‡ï¼š1) <strong class="term">é¡¹ç›®é—´å¯¹æ¯”æŸå¤±ï¼ˆItem-to-Item Lossï¼‰</strong>å¯¹é½ç›¸ä¼¼é¡¹ç›®ï¼›2) <strong class="term">æ ‡é¢˜ç”ŸæˆæŸå¤±ï¼ˆCaption Lossï¼‰</strong>é˜²æ­¢æ¨¡å‹å¹»è§‰ã€‚æœ€ç»ˆé€šè¿‡<strong class="term">RQ-Kmeans</strong>å°†è¡¨ç¤ºç¦»æ•£åŒ–ä¸ºè¯­ä¹‰IDã€‚</p>
</div>

<h2>å†…å®¹ç¿»è¯‘</h2>

<h3>æŠ¥å‘Šæ ‡é¢˜</h3>
<div class="original">OneRec Technical Report</div>
<div class="translation">OneRecæŠ€æœ¯æŠ¥å‘Š</div>

<h3>å›¾3è¯´æ˜</h3>
<div class="original figure">
  Figure 3|Illustration of our tokenizer implementation. We first align multimodal representations of item pairs with high collaborative similarity to obtain collaborative multimodal representations, then tokenize these representations into discrete semantic IDs using RQ-Kmeans.
  <br><br>
  Caption + Tag + OCR + ASR#extremesports#skiing Skiing Showcase miniCPM-V-8Bâ€¦QFormerLLaMA3<br>
  Ã—ğ‘!<br>
  miniCPM-V-8Bâ€¦QFormerLLaMA3<br>
  Caption + Tag + OCR + ASR#skiing #extremesports#snowboarding<br>
  Item Pairs ğ’Ÿ! 1 Cover + 5 Frames1 Cover + 5 Frames<br>
  K / VK / VQQÃ—ğ‘!-=Codebook 1Codebook 2Codebook 3-=-=Item semantic identifiers (3, 4, 1)centroidK-means Clusteringğ‘µ! query tokens ğğ’Š<br>
  ğ‘µ! query tokens ğğ’Šğ’„$$ğ’„%$ğ’„&$ğ’„'$Nearest Code Search<br>
  Nearest Code SearchNearest Code Searchğ’„$%ğ’„%%ğ’„&%ğ’„'%ğ’„$&ğ’„%&ğ’„&&ğ’„'&<br>
  ğ’„##ğ’„$#ğ’„%#ğ’„&#<br>
  ğ’„$%ğ’„#%ğ’„%%ğ’„&%compressed tokens &ğŒcompressed tokens &ğŒ<br>
  ğ’„&&ğ’„#&ğ’„%&ğ’„$&<br>
  â„’!&'_)*'â„’!&'_)*'â„’+,+ğŒğŒ
</div>
<div class="translation figure">
  å›¾3|æˆ‘ä»¬çš„åˆ†è¯å™¨å®ç°ç¤ºæ„å›¾ã€‚é¦–å…ˆå¯¹é½å…·æœ‰é«˜ååŒç›¸ä¼¼æ€§çš„é¡¹ç›®å¯¹çš„å¤šæ¨¡æ€è¡¨ç¤ºä»¥è·å¾—ååŒå¤šæ¨¡æ€è¡¨ç¤ºï¼Œç„¶åä½¿ç”¨RQ-Kmeanså°†è¿™äº›è¡¨ç¤ºæ ‡è®°ä¸ºç¦»æ•£è¯­ä¹‰IDã€‚<br><br>
  æ ‡é¢˜ + æ ‡ç­¾ + OCR + ASR#æé™è¿åŠ¨#æ»‘é›ª æ»‘é›ªå±•ç¤º miniCPM-V-8Bâ€¦QFormerLLaMA3<br>
  Ã—ğ‘!<br>
  miniCPM-V-8Bâ€¦QFormerLLaMA3<br>
  æ ‡é¢˜ + æ ‡ç­¾ + OCR + ASR#æ»‘é›ª #æé™è¿åŠ¨#æ»‘é›ªæ¿<br>
  é¡¹ç›®å¯¹ ğ’Ÿ! 1å°é¢+5å¸§ 1å°é¢+5å¸§<br>
  K/V K/V Q QÃ—ğ‘! -=ç æœ¬1 ç æœ¬2 ç æœ¬3 -= -=é¡¹ç›®è¯­ä¹‰æ ‡è¯†ç¬¦(3,4,1)è´¨å¿ƒKå‡å€¼èšç±»ğ‘µ!æŸ¥è¯¢ä»¤ç‰Œğğ’Š<br>
  ğ‘µ!æŸ¥è¯¢ä»¤ç‰Œğğ’Š ğ’„$$ğ’„%$ğ’„&$ğ’„'$æœ€è¿‘ç æœç´¢<br>
  æœ€è¿‘ç æœç´¢ æœ€è¿‘ç æœç´¢ ğ’„$%ğ’„%%ğ’„&%ğ’„'%ğ’„$&ğ’„%&ğ’„&&ğ’„'&<br>
  ğ’„##ğ’„$#ğ’„%#ğ’„&#<br>
  ğ’„$%ğ’„#%ğ’„%%ğ’„&%å‹ç¼©ä»¤ç‰Œ&ğŒå‹ç¼©ä»¤ç‰Œ&ğŒ<br>
  ğ’„&&ğ’„#&ğ’„%&ğ’„$&<br>
  â„’!&'_)*'â„’!&'_)*'â„’+,+ğŒğŒ
</div>

<h3>å¤šæ¨¡æ€è¡¨ç¤º</h3>
<div class="original">
  â€¢Multimodal Representations. We incorporate multimodal inputs for each video: the caption, tag, ASR (speech-to-text), OCR (image-to-text), the cover image, and 5 uniformly sampled frames. These inputs are processed using miniCPM-V-8B (Hu et al., 2024), generating \(N_M=1280\) token vectors \(\mathbf{M} \in \mathbb{R}^{N_M \times d_t}\) (\(d_t=512\)). A Querying Transformer (QFormer) (Li et al., 2023) then compresses these tokens with \(\tilde{N}_M=4\) learnable query tokens \(\mathbf{Q}^{(1)} \in \mathbb{R}^{\tilde{N}_M \times d_t}\):
  \[\mathbf{Q}^{(i+1)} = \text{CrossAttn}\left( \mathbf{Q}^{(i)}, \mathbf{M}, \mathbf{M} \right),\quad (1)\]
  \[\mathbf{Q}^{(i+1)} = \text{FFN}\left( \text{RMSNorm}\left( \mathbf{Q}^{(i+1)} \right) \right), \quad \text{for } i \in \{1,2,...,N_c\},\quad (2)\]
  where \(\tilde{\mathbf{M}} = \mathbf{Q}^{(N_c+1)} \in \mathbb{R}^{\tilde{N}_M \times d_t}\) denotes the compressed version of \(\mathbf{M}\), and \(N_c=4\) denotes the number of QFormer layers.
</div>
<div class="translation">
  â€¢å¤šæ¨¡æ€è¡¨ç¤ºã€‚æˆ‘ä»¬æ•´åˆæ¯ä¸ªè§†é¢‘çš„å¤šæ¨¡æ€è¾“å…¥ï¼šæ ‡é¢˜ã€æ ‡ç­¾ã€ASRï¼ˆè¯­éŸ³